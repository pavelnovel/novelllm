{"timestamp": "2023-11-30 03:50:01", "text": "I love seeing things break. Because how else would we put them back together? I got this idea from a recent paper highlighting security vulnerabilities with ChatGPT repeating content verbatim from its training data (which can contain personally identifiable information and other things that OpenAI doesn't want out). For anyone who is curious, the paper's in the comments. The less nefarious take is that this also happens if you repeat the same word over and over. Eventually, it begins to sound weird and lose its immediate meaning. Poor ChatGPT just gets confused sometimes. (There should be a sad robot emoji.) Also, I appreciate the timeless tendency of humans to always mess with things. A little poke here, a prod there, and before you know it we have fire, steam, and we're going to space. PS: this seems to only work with GPT 3.5. GPT 4 didn't want to play that game with me."}